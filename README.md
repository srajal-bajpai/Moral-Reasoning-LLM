# Insights into Moral Reasoning Capabilities of AI: A Comparative Study between Humans and Large Language Models
This repository hosts the code, data, and supplementary materials for our research article, "Insights into Moral Reasoning Capabilities of AI: A Comparative Study between Humans and Large Language Models (LLMs)." This study examines and compares moral reasoning in humans and AI-based chatbots, specifically investigating biases within LLMs such as ChatGPT, Google Bard, and Bing Chat.

## Background
With LLMs becoming integral to fields like healthcare, education, and legal support, understanding their ethical implications is increasingly essential. Our research explores if LLMs engage in genuine moral reasoning or simply replicate pre-existing biases. We utilize two psychological tools:

## Moral Competence Test (MCT): Evaluates participants' moral judgment consistency.
## Moral Foundations Questionnaire (MFQ): Assesses alignment with moral values like Care, Loyalty, and Authority.

The findings reveal that LLMs demonstrate moral inclinations favoring individualistic principles, suggesting a potential risk when AI influences human moral decision-making processes, especially in areas that require ethical neutrality.

## Repository Contents
Data: Contains anonymized datasets from human participants and LLM outputs on MCT and MFQ tests.
Code: Python scripts for statistical analyses, including one-way ANOVA and post hoc comparisons.
